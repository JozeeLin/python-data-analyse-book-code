# 金融和经济数据应用

[TOC]

> "截面"(cross-section)表示某个时间点的数据。例如，标普500指数中所有成分股在特定日期的收盘价就形成了一个截面。多个数据项(例如价格和成交量)在多个时间点的截面数据构成一个面板(panel)。面板数据既可以表示为层次化索引的DataFrame，也可以表示为三维的Panel pandas对象。

## 数据规整化方面的话题

### 时间序列以及截面对齐

```python
prices = pd.read_csv('ch09/stock_px.csv',
                       parse_dates=True,index_col=0)
volume = pd.read_csv('ch11/volume.csv',parse_dates=True,index_col=0)
prices_new = prices[['AAPL','JNJ','SPX','XOM']]
volume_new = volume[['AAPL','JNJ','XOM']]
(prices_new*volume_new)[:5]
vwap = (prices_new*volume_new).sum()/volume_new.sum()
vwap.dropna()
#手工进行对齐，使用DataFrame.align方法，返回一个元组含有两个对象的重索引版本
prices_new.align(volume_new,join='inner')

s1 = Series(range(3), index=['a','b','c'])
s2 = Series(range(4), index=['d','b','c','e'])
s3 = Series(range(3), index=['f','a','c'])
DataFrame({'one':s1,'two':s2,'three':s3})
DataFrame({'one':s1,'two':s2,'three':s3}, index=list('face'))
```

### 频率不同的时间序列的运算

> 频率转换和重对齐的两个大主要工具是resample和reindex方法。resample用于将数据转换到固定频率，而reindex则用于使数据符合一个新索引。它们都支持插值(如前向填充)逻辑。

```python
ts1 = Series(np.random.randn(3),
            index=pd.date_range('2012-6-13', periods=3, freq='W-WED'))
#重采样到工作日(星期一到星期五)频率,则那些没有数据的日子就会出现一个"空洞"
ts1.resample('B')
#ffill表示使用前面的值填充这些空白。通常用于处理低频率的数据，使得各时间点都有一个最新的有效值
ts1.resample('B').ffill()
#将较低频率的数据升采样到较高的规整频率。对于不规整样本的时间序列
dates = pd.DatetimeIndex(['2012-6-12','2012-6-17','2012-6-18',
                     '2012-6-21','2012-6-22','2012-6-29'])
ts2 = Series(np.random.randn(6), index=dates)
#将ts1中'最当前'的值(即前向填充)加到ts2上。方法为将两者重采样为规整频率后再相加。如果要维持ts2中的日期索引，则reindex会是一种更好的解决方案。
ts1.reindex(ts2.index, method='ffill')#先进行数据索引对齐
ts2 + ts1.reindex(ts2.index, method='ffill')
#Period(表示时间区间)提供了另一种处理不同频率时间序列的方法，尤其是有着特殊规范的以年或季度为频率的金融或经济序列。

#GDP的宏观经济时间序列
gdp = Series([1.78,1.94,2.08,2.01,2.15,2.31,2.46],
            index=pd.period_range('1984Q2',periods=7,freq='Q-SEP'))
#通货膨胀的宏观经济时间序列,每年年末观测值
infl = Series([0.025,0.045,0.037,0.04],
             index=pd.period_range('1982',periods=4, freq='A-DEC'))
#由Period索引的两个不同频率的时间序列之间的运算必须进行显式转换
infl_q = infl.asfreq('Q-SEP',how='end') #转换到Q-SEP以得到该频率下的正确时期
infl_q.reindex(gdp.index, method='ffill')
```

### 时间和'最当前'数据选取

> 假设有一个很长的盘中市场数据时间序列，现在希望抽取其中每天特定时间的价格数据。

```python
#生成一个交易日内的日期范围和时间序列
rng = pd.date_range('2012-06-01 09:30','2012-06-01 15:59', freq='T')
#生成4天的时间点
rng = rng.append([rng+pd.offsets.BDay(i) for i in range(1,4)])
ts = Series(np.arange(len(rng), dtype=float), index=rng)
#利用Python的datetime.time对象进行索引即可抽取出这些时间点上的值
ts[time(10,0)]#每天10点的数据值
ts.at_time(time(10,0)) #等效于上一句
#选取两个time对象之间的值
ts.between_time(time(10,0), time(10,1))
#将该时间序列的大部分内容随机设置为NA
indexer = np.sort(np.random.permutation(len(ts))[700:])
irr_ts = ts.copy()
irr_ts[indexer] = np.nan
irr_ts['2012-06-01 09:50':'2012-06-01 10:00']
#将一组timestamp传入asof方法，可以的到这些时间点处(或其之前最近)的有效值(非NA)
selection = pd.date_range('2012-06-01 10:00', periods=4, freq='B')
#构造一个日期范围(每天上午10点)
irr_ts.asof(selection)
```

### 拼接多个数据源

> - 在一个特定的时间点上，从一个数据源切换到另一个数据源
> - 用另一个时间序列对当前时间序列中的缺失值'打补丁'
> - 将数据中的符号(国家、资产代码等)替换为实际数据

```python
#情况一：使用pandas.concat将两个TimeSeries或DataFrame对象合并到一起
data1 = DataFrame(np.ones((6,3), dtype=float),
                 columns=['a','b','c'],
                 index=pd.date_range('6/12/2012', periods=6))
data2 = DataFrame(np.ones((6,3), dtype=float)*2,
                 columns=['a','b','c'],
                 index=pd.date_range('6/13/2012',periods=6))
spliced = pd.concat([data1.loc[:'2012-06-14'], data2.loc['2012-06-15':]])
#假设data1缺失了data2中存在的某个时间序列
data2 = DataFrame(np.ones((6,4), dtype=float)*2,
                 columns=['a','b','c','d'],
                 index=pd.date_range('6/13/2012',periods=6))
spliced = pd.concat([data1.loc[:'2012-06-14'],data2.loc['2012-06-15':]])
#combine_first可以引入合并点之前的数据，这样也就扩展了'd'项的历史
spliced_filled = spliced.combine_first(data2)
#就地更新。如果只想填充空洞，则必须传入overwrite=False才行
spliced.update(data2, overwrite=False)#等效于上一句
#数据中的符号替换为实际数据。使用DataFrame的列索引操作得到等效于上面操作的效果
cp_spliced = spliced.copy()
cp_spliced[['a','c']] = data1[['a','c']]
```

### 收益指数和累计收益

> 收益(return)通常指的是某资产价格的百分比变化。收益指数表示单位投资(比如1美元)收益的时间序列。

```python
aapl_data = web.DataReader('AAPL', 'yahoo')
#2011年到2012年间苹果公司的股票价格数据
price = aapl_data.loc['2011-01-01':'2012-07-27',:]['Adj Close']
#计算两个时间点之间的累计百分比回报只需计算价格的百分比变化
price['2011-10-03']/price['2011-3-01'] - 1
#收益指数
returns = price.pct_change()
ret_index = (1+returns).cumprod()
ret_index[0] = 1

#得到ret_index(收益指数)，计算指定时期内的累计收益
m_returns = ret_index.resample('BM').last().pct_change()
m_returns['2012']

#使用重采样聚合从日百分比变化中计算得出
m_rets = (1+returns).resample('M', kind='period').prod() - 1
m_rets['2012']
```

## 分组变换和分析

```python
#随机生成1000个股票代码
N = 1000
def rands(n):
    choices = string.ascii_uppercase
    return ''.join([random.choice(choices) for _ in xrange(n)])
tickers = np.array([rands(5) for _ in xrange(N)])

#创建一个含有3列的DataFrame来承载这些假想数据，只选择部分股票组成该投资组合
M = 500
df = DataFrame({'Momentum':np.random.randn(M)/200+0.03,
               'Value':np.random.randn(M)/200+0.08,
               'ShortInterest':np.random.randn(M)/200-0.02},
              index=tickers[:M])
#为这些股票随机创建一个行业分类。
ind_names = np.array(['FINANCIAL','TECH'])
sampler = np.random.randint(0, len(ind_names), N)
industries = Series(ind_names[sampler], index=tickers,name='industry')
#根据行业分类进行分组并执行分组聚合和变换
by_industry = df.groupby(industries)
by_industry.mean()
by_industry.describe()
#行业内标准化处理
def zscore(group):
    return (group-group.mean())/group.std()
df_stand = by_industry.apply(zscore)
#处理之后，各行业的平均值为0,标准差为1
df_stand.groupby(industries).agg(['mean','std'])
#行业内降序排名
ind_rank = by_industry.rank(ascending=False)
ind_rank.groupby(industries).agg(['min','max'])
#'排名和标准化'是一种很常见的变换运算组合。通过将rank和zscore链接在一起即可完成整个变换过程。
#行业内排名和标准化
by_industry.apply(lambda x:zscore(x.rank()))
```

### 分组因子暴露

> 因子分析(factor analysis)是投资组合定量管理中的一种技术。投资组合的持有量和性能(收益与损失)可以被分解为一个或多个表示投资组合权重的因子(风险因子就是其中之一)。
>
> 例如，某只股票的价格与某个基准(比如标普500指数)的协动性被称为其贝塔风险系数(beta)

```python

```



## 更多示例应用

